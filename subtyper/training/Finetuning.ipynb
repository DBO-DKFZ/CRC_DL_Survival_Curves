{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15b541a-9a64-40e6-a0c4-cdd72737a081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import timm\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import Normalize\n",
    "from torchmetrics import Accuracy, ConfusionMatrix \n",
    "\n",
    "from fastcore.foundation import L\n",
    "from collections import OrderedDict\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "import seaborn as sns\n",
    "\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4f45e4-1688-4729-816b-aa290281256e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tile_column = 'tiles'\n",
    "label_column = 'label'\n",
    "gpu = '0,'\n",
    "epochs = 100\n",
    "learning_rate = 1e-05\n",
    "batch_size = 700\n",
    "exp_name = \"TissueClassification_fine_tuning_DACHS_all_norm_CJ\"\n",
    "\n",
    "train_pkl = '/.../datasets/df_train.pkl' # The NCT-CRC-HE-100K \n",
    "val_pkl = '/.../df_val.pkl' # The NCT-CRC-HE-100K \n",
    "kather_int_test_pkl = '/.../datasets/df_test.pkl' #The NCT-CRC-HE-100K \n",
    "kather_ext = '/.../datasets/TissueClasses_CRC_VAL_7K.pkl'\n",
    "\n",
    "# validation set \n",
    "finetune_val_pkl = '/.../datasets/df_finetune_val_dachs_ideal_norm.pkl' # samples of the DACHS patient cohort, annotated in-house\n",
    "finetune_train_pkl = '/.../datasets/df_finetune_train_dachs_all_norm.pkl'# samples of the DACHS patient cohort, annotated in-house "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6a533-aa16-4acb-9c67-44fe69d5c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "\n",
    "train_tfms = transforms.Compose([ \n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomApply(torch.nn.ModuleList([transforms.ColorJitter(brightness=0.25, contrast=0.75, saturation=0.25, hue=0.5)]), p=0.9),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    transforms.RandomApply(torch.nn.ModuleList([transforms.GaussianBlur(kernel_size=(5,5), sigma=(0.1,5))]), p=0.3),\n",
    "    ToTensor(),\n",
    "    norm,\n",
    "])\n",
    "\n",
    "\n",
    "test_tfms = transforms.Compose([\n",
    "    ToTensor(),\n",
    "    norm,\n",
    "])\n",
    "\n",
    "\n",
    "class SlideDataSet(Dataset):\n",
    "    def __init__(self, dataframe,tile_column, label_column, tile_tfms):\n",
    "        self.df = dataframe\n",
    "        self.tiles = L(*self.df[tile_column])\n",
    "        self.labels = torch.as_tensor(self.df[label_column].astype(int).values)\n",
    "        self.tile_tfms = tile_tfms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.tiles[index]) \n",
    "        label = self.labels[index]\n",
    "        return self.tile_tfms(image), label \n",
    "    \n",
    "class SlideDataModule(pl.LightningDataModule): \n",
    "    def __init__(self, train, val, test, tile_column, label_column, batch_size, train_tfms, test_tfms):\n",
    "        super().__init__()\n",
    "        self.train = train\n",
    "        self.val = val\n",
    "        self.test = test\n",
    "        self.tile_column = tile_column\n",
    "        self.label_column = label_column\n",
    "        self.bs = batch_size \n",
    "        self.train_tfms = train_tfms\n",
    "        self.test_tfms = test_tfms\n",
    "       \n",
    "        \n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "    \n",
    "    def setup(self, stage): \n",
    "        if stage == \"fit\": \n",
    "            self.train_df = pd.read_pickle(self.train)\n",
    "            self.valid_df =  pd.read_pickle(self.val)\n",
    "            self.train_ds = SlideDataSet(self.train_df, self.tile_column, self.label_column, self.train_tfms) \n",
    "            self.valid_ds = SlideDataSet(self.valid_df, self.tile_column, self.label_column, self.test_tfms)\n",
    "        if stage == \"test\":\n",
    "            self.test_df = pd.read_pickle(self.test)\n",
    "            self.test_ds = SlideDataSet(self.test_df, self.tile_column, self.label_column, self.test_tfms)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_ds, shuffle=True, batch_size=self.bs, batch_sampler=None, num_workers=6)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.valid_ds, shuffle=False, batch_size=self.bs, batch_sampler=None, num_workers=6)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_ds, shuffle=False, batch_size=self.bs, batch_sampler=None, num_workers=6)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f21f1c-3d80-455d-815a-179185e44a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlideModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Metrics \n",
    "        self.train_acc = Accuracy()\n",
    "        self.valid_acc = Accuracy()\n",
    "        self.test_acc = Accuracy()\n",
    "\n",
    "        \n",
    "        model = timm.create_model('resnet18')\n",
    "        model.fc = nn.Conv2d(512,1,1)\n",
    "        model_dir = '/.../' # add path to nvidia-checkpoint\n",
    "        ckpt = torch.load(os.path.join(model_dir, \"nvidia-resnet18.pt\"), map_location=\"cpu\")\n",
    "        model.load_state_dict(OrderedDict(zip(model.state_dict().keys(), ckpt.values())))\n",
    "        model.reset_classifier(0)\n",
    "        \n",
    "        self.model = model \n",
    "        self.classifier = nn.Sequential(nn.Dropout(0.70), nn.Linear(512*1, 9))\n",
    "        \n",
    "        \n",
    "    def forward(self, tiles, label): \n",
    "        rep = self.model(tiles)\n",
    "        y_prob = self.classifier(rep)\n",
    "        return y_prob, label   \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        tiles, y = batch\n",
    "        logits, y = self(tiles, y) \n",
    "        logits = logits.squeeze(1).float()\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.log(\"train/acc\", self.train_acc(logits.sigmoid(), y),on_step=False, on_epoch=True, logger=True)\n",
    "        self.log(\"train/loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {\n",
    "        \"loss\": loss, \n",
    "        \"slide_score\": logits.detach().sigmoid(), \n",
    "        \"y\": y.detach()\n",
    "        }\n",
    "    \n",
    "    def training_epoch_end(self, outs):\n",
    "        pass\n",
    "\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        tiles, y = batch\n",
    "        logits, y = self(tiles, y)\n",
    "        logits = logits.squeeze(1).float()\n",
    "        #print(logits, y)\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.log(\"valid/acc\", self.valid_acc(logits.sigmoid(), y), on_epoch=True, logger=True)\n",
    "        self.log(\"valid/loss\", loss)\n",
    "        return {\n",
    "        \"loss\": loss, \n",
    "        \"slide_score\": logits.detach().sigmoid(), \n",
    "        \"y\": y.detach()\n",
    "        }\n",
    "    \n",
    "    def validation_epoch_end(self, outs):\n",
    "        pass\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.validation_step(batch, batch_idx)\n",
    "    \n",
    "    def test_epoch_end(self, outs):\n",
    "        return self.validation_epoch_end(outs)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.AdamW(self.parameters(), lr = learning_rate, weight_decay=0.000001)\n",
    "        return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd3975c-2d27-45c5-aa9d-4a9f0b3fea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlideModel_Finetune(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Metrics \n",
    "        self.train_acc = Accuracy()\n",
    "        self.valid_acc = Accuracy()\n",
    "        self.test_acc = Accuracy()\n",
    "        self.cm = ConfusionMatrix(num_classes=9)\n",
    "\n",
    "        self.model = model.model\n",
    "        # split model into seperate blocks to decide which to fine-tune?\n",
    "        self.model_part1 =  nn.Sequential(*list(self.model.children())[:-3])\n",
    "        last_resblock = nn.Sequential(*list(self.model.children())[7])\n",
    "        self.basicblock0 = nn.Sequential(list(last_resblock.children())[0])\n",
    "        self.basicblock1 = nn.Sequential(list(last_resblock.children())[1])\n",
    "        self.model_part2 =  nn.Sequential(*list(self.model.children())[8:])\n",
    "        self.classifier = model.classifier\n",
    "        \n",
    "        self.model_part1.requires_grad_(True)\n",
    "        self.basicblock0.requires_grad_(True) \n",
    "        self.basicblock1.requires_grad_(True)\n",
    "        self.model_part2.requires_grad_(True)\n",
    "        self.classifier.requires_grad_(True)\n",
    "        \n",
    "        \n",
    "    def forward(self, tiles, label): \n",
    "        #rep = self.model(tiles)\n",
    "        tiles = self.model_part1(tiles)\n",
    "        tiles = self.basicblock0(tiles)\n",
    "        tiles = self.basicblock1(tiles)\n",
    "        rep = self.model_part2(tiles)\n",
    "        y_prob = self.classifier(rep)\n",
    "        return y_prob, label   \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        tiles, y = batch\n",
    "        logits, y = self(tiles, y) \n",
    "        logits = logits.squeeze(1).float()\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.cm.update(logits.sigmoid().float(), y)\n",
    "        self.log(\"train/acc\", self.train_acc(logits.sigmoid(), y),on_step=False, on_epoch=True, logger=True)\n",
    "        self.log(\"train/loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {\n",
    "        \"loss\": loss, \n",
    "        \"slide_score\": logits.detach().sigmoid(), \n",
    "        \"y\": y.detach()\n",
    "        }\n",
    "    \n",
    "    def training_epoch_end(self, outs):\n",
    "        cm_results = self.cm.compute()\n",
    "        pass\n",
    "\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        tiles, y = batch\n",
    "        logits, y = self(tiles, y)\n",
    "        logits = logits.squeeze(1).float()\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.cm.update(logits.sigmoid().float(), y)\n",
    "        self.log(\"valid/acc\", self.valid_acc(logits.sigmoid(), y), on_epoch=True, logger=True)\n",
    "        self.log(\"valid/loss\", loss)\n",
    "        return {\n",
    "        \"loss\": loss, \n",
    "        \"slide_score\": logits.detach().sigmoid(), \n",
    "        \"y\": y.detach()\n",
    "        }\n",
    "    \n",
    "    def validation_epoch_end(self, outs):\n",
    "        cm_results = self.cm.compute()\n",
    "        return {\n",
    "            \"cm_resuts\": cm_results.detach()\n",
    "        }\n",
    "        \n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.validation_step(batch, batch_idx)\n",
    "    \n",
    "    def test_epoch_end(self, outs):\n",
    "        return self.validation_epoch_end(outs)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.AdamW(self.parameters(), lr = learning_rate, weight_decay=1e-07) # lr=0.00001, wd = 0.00001\n",
    "        return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf2f783-5274-463c-9c78-d1ebeff69f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Experiment name', exp_name)\n",
    "df_train = pd.read_pickle(train_pkl)\n",
    "df_val = pd.read_pickle(val_pkl)\n",
    "df_test = pd.read_pickle(kather_int_test_pkl)\n",
    "print('Size of Training/Validation/Testset: {}/{}/{}'.format(len(df_train), len(df_val), len(df_test)))\n",
    "\n",
    "# load the checkpoint after training on NCT-CRC-HE-100K \n",
    "ckpt = '/.../checkpoints/epoch=99-step=66699.ckpt'\n",
    "m0 = SlideModel()\n",
    "m0 = m0.load_from_checkpoint(ckpt, strict=False)\n",
    "m0 = m0.eval() \n",
    "m0.freeze()\n",
    "dm1 = SlideDataModule(train_pkl, val_pkl, kather_ext, tile_column, label_column, batch_size, train_tfms, test_tfms) \n",
    "dm1.setup('test')\n",
    "trainer = pl.Trainer(gpus=gpu, callbacks=False)\n",
    "metrics = trainer.test(m0, datamodule=dm1, verbose=True)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08436b6d-544a-44c8-928c-d3fe917c50cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = SlideDataModule(finetune_train_pkl, finetune_val_pkl, kather_int_test_pkl, tile_column, label_column, batch_size, train_tfms, test_tfms)\n",
    "dm.setup('fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62418f7e-dc73-4083-a4eb-c03e8ed06afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = SlideModel_Finetune(m0)\n",
    "\n",
    "logg_path = os.path.join(os.getcwd(), \"logs\", exp_name)\n",
    "logger = pl.loggers.TensorBoardLogger(logg_path, name=None)\n",
    "monitor = \"valid/loss\"\n",
    "monitor_mode = \"min\"\n",
    "lr_monitor = pl.callbacks.lr_monitor.LearningRateMonitor()\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(save_last=True)\n",
    "trainer = pl.Trainer(gpus=gpu,  callbacks=[checkpoint_callback, lr_monitor], logger=logger, num_sanity_val_steps=0, max_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e74e486-d26c-4e6c-83ed-468959fe0a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(m, datamodule=dm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
